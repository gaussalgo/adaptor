{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised vs. Supervised Machine Translation\n",
    "\n",
    "In this tutorial, we'll use Adaptor to look at the **difference in accuracy** when training domain-specific translator using standard **Supervised** vs. **Unsupervised objectives**. We'll also use one extra domain to estimate the distributional **robustness** of our translator throughout the adaptation.\n",
    "\n",
    "* For the supervised adaptation and evaluations, we'll use standard *Sequence2Sequence* (i.e. MLE) objective.\n",
    "* For the unsupervised adaptation, we'll use Adaptor's unsupervised *BackTranslation* objectice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SB2KDo6-XP7l",
    "outputId": "c4b6be6a-af86-42f9-d433-d13e2c94d7aa"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "!git clone https://github.com/gaussalgo/adaptor.git\n",
    "!pip install -e adaptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the utils directory to the working directory, so we can easily import it\n",
    "!mv adaptor/examples ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset resolution\n",
    "\n",
    "We will use Adaptor's `OPUSDataset` wrapper available in [/examples](https://github.com/gaussalgo/adaptor/blob/master/examples/data_utils_opus.py) of github repo. For a supported set of domains, this wrapper will download or reload the cached dataset and parse it into `source` and `target` list of strings. New domains can be added by [adding their urls](https://github.com/gaussalgo/adaptor/blob/db33e6e439babc68fe801a8946d87116ff44f170/examples/data_utils_opus.py#L10) from [https://opus.nlpl.eu](https://opus.nlpl.eu/).\n",
    "\n",
    "Note that `data_utils_opus.py` also takes care of deduplicating the datasets - if the sample of given source text was already loaded, it will be skipped in the next-loaded `OPUSDataset`s. This is to make sure that no data leakage between train and validation splits exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping 82264 duplicates from wikimedia train split.\n",
      "Dropping 10283 duplicates from wikimedia val split.\n",
      "Dropping 10284 duplicates from wikimedia test split.\n",
      "Dropping 33877148 duplicates from OpenSubtitles train split.\n",
      "Dropping 4234644 duplicates from OpenSubtitles val split.\n",
      "Dropping 4234644 duplicates from OpenSubtitles test split.\n"
     ]
    }
   ],
   "source": [
    "from examples.data_utils_opus import OPUSDataset\n",
    "\n",
    "src_lang = \"cs\"\n",
    "tgt_lang = \"en\"\n",
    "\n",
    "data_dir = \"examples\"\n",
    "\n",
    "val_size = 100\n",
    "test_size = 1000\n",
    "\n",
    "wiki_pairs = OPUSDataset(\"wikimedia\", \"train\", src_lang, tgt_lang, data_dir=data_dir)\n",
    "wiki_val_pairs = OPUSDataset(\"wikimedia\", \"val\", src_lang, tgt_lang, data_dir=data_dir, firstn=val_size)\n",
    "wiki_test_pairs = OPUSDataset(\"wikimedia\", \"test\", src_lang, tgt_lang, data_dir=data_dir, firstn=test_size)\n",
    "\n",
    "opensub_pairs = OPUSDataset(\"OpenSubtitles\", \"train\", src_lang, tgt_lang, data_dir=data_dir, firstn=val_size)\n",
    "opensub_val_pairs = OPUSDataset(\"OpenSubtitles\", \"val\", src_lang, tgt_lang, data_dir=data_dir, firstn=val_size)\n",
    "opensub_test_pairs = OPUSDataset(\"OpenSubtitles\", \"test\", src_lang, tgt_lang, data_dir=data_dir, firstn=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ukrajinsk√Ω l√©ka≈ô ortoped-traumatologist nejvy≈°≈°√≠ kategorie, MUDr, vedouc√≠ v√Ωzkumn√≠k z kloubn√≠ch onemocnƒõn√≠ u dospƒõl√Ωch st√°tn√≠ instituce \"Instituce traumatologie a ortopedie NAMS Ukrajiny\"',\n",
       " 'Martha Elefteriadu (* 12. z√°≈ô√≠ 1946 Bulkes, Jugosl√°vie) je ƒçesk√° zpƒõvaƒçka ≈ôeck√©ho p≈Øvodu, polovina pƒõveck√©ho dua Martha a Tena, kter√© ji≈æ od ml√°d√≠ tvo≈ô√≠ se svoj√≠ sestrou Tenou Elefteriadu.',\n",
       " '≈Ωivotopis',\n",
       " 'Poch√°z√≠ z rodiny ≈ôeck√Ωch emigrant≈Ø, je≈æ uprchla z ≈òecka kv≈Øli obƒçansk√© v√°lce a usadila se v roce 1950 v nƒõkdej≈°√≠m ƒåeskoslovensku.',\n",
       " 'Jejich maminka zem≈ôela brzy v dƒõtstv√≠ a obƒõ d√≠vky vyr≈Østaly v dƒõtsk√©m domovƒõ pro ≈ôeck√© dƒõti v Ivanƒçic√≠ch.',\n",
       " 'Martha po maturitƒõ na gymn√°ziu studovala nejprve medicinu, pozdƒõji p≈ôestoupila na studium psychologie, kter√© dokonƒçila na Karlovƒõ univerzitƒõ v Praze.',\n",
       " 'Koncem ≈°edes√°t√Ωch let se obƒõ sestry seznamuj√≠ s kytaristou Ale≈°em Sigmundem ze skupiny Vulk√°n, kter√Ω obƒõma zpƒõvaƒçk√°m pom√°h√° vytvo≈ôit pevn√© autorsk√© a muzikantsk√© z√°zem√≠.',\n",
       " 'Jejich prvn√≠ nahr√°vky poch√°zej√≠ z roku 1968, v roce 1970 vyd√°vaj√≠ svoji prvn√≠ LP dlouhohraj√≠c√≠ desku u vydavatelstv√≠ Panton D√°l ne≈æ slunce vst√°v√°.',\n",
       " 'Od t√© doby jsou obƒõ sestry st√°licemi ƒçesk√© popul√°rn√≠ hudby.',\n",
       " 'Za dobu sv√©ho p≈Øsoben√≠ zde spolupracovaly s celou ≈ôadou renomovan√Ωch umƒõlc≈Ø.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_pairs.source[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ this is a default format of the **samples** of Sequence2Sequence and inherited objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ukrainian doctor orthopedic traumatologist highest category, Doctor of Medical Science, senior researcher of joint disease of adults of government institution \"Institute of Traumatology and Orthopedics NAMS Ukraine\"',\n",
       " 'Martha a Tena is a Czech music duo whose members are sisters Martha Elefteriadu and Tena Elefteriadu. Martha Elefteriadu (* 12. z√°≈ô√≠ 1946 Bulkes, Jugosl√°vie) is a Czech singer of ≈ôeck√©ho p≈Øvodu, half of the duo Martha a Tena, together with her sister Tena Elefteriadu. Tena Elefteriadu, born as Partena Elefteriadu (*16.',\n",
       " 'Personal Life',\n",
       " 'Their family emigrated from ≈òecka because of the obƒçansk√© v√°lce and settled in 1950 in former ƒåeskoslovensku.',\n",
       " 'Their mother died while they were children, so they grew up in a dƒõtsk√©m domovƒõ for Greek immigrants in Ivanƒçic√≠ch.',\n",
       " 'Martha, after maturitƒõ at a gymn√°ziu studied first general medicine, then changed major to psychologie, and graduated from Karlovƒõ univerzitƒõ in Prague.',\n",
       " \"Tena has a son Marko Elefteriadis, a rapper who performs under stage name Ektor. Career At the end of the 1960's the sisters met a guitarist Ale≈° Sigmund from band Vulk√°n, who helped them create strong autorsk√© and muzikantsk√© foundations.\",\n",
       " 'Their first records are from 1968, in 1970 they released their first LP dlouhohraj√≠c√≠ desku with Panton D√°l ne≈æ slunce vst√°v√°.',\n",
       " 'They quickly established themselves in Czech popul√°rn√≠ hudby.',\n",
       " 'They collaborated with a series of famous artists.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_pairs.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ this is a default format of the **labels** of Sequence2Sequence and inherited objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our base translator for adaptation, we pick a general Helsinki-NLP model. This model has an architecture of the Transformer-base and has been pre-trained on a bulk dump of a subset of OPUS domains. Likely, it has already been exposed to our domains of adaptation and evaluation (Wiki & OpenSubtitles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptor.lang_module import LangModule\n",
    "\n",
    "lang_module = LangModule(\"Helsinki-NLP/opus-mt-%s-%s\" % (src_lang, tgt_lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the training, we evaluate model's BLEU. \n",
    "\n",
    "Using the identical interface, Adaptor allows you to evaluate any of other generative measures, that can better fit your task. Alternatively, you can relatively easily also implement your own generative evaluator. \n",
    "Take a look [here](https://github.com/gaussalgo/adaptor/blob/db33e6e439babc68fe801a8946d87116ff44f170/adaptor/evaluators/generative.py).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptor.evaluators.generative import BLEU\n",
    "\n",
    "evaluators = [BLEU(additional_sep_char=\"‚ñÅ\", decides_convergence=True)]  # \"‚ñÅ\" is a specific separation token that sometimes relains left after output decoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised adaptation\n",
    "\n",
    "In the first experiment, we use standard Sequence2Sequence (also used under a name MLE -Maximum Likelihood Estimation- objective). This objective maximises probability of every subsequent token under the assuptions of given input and the coreectly-generated preceding output.\n",
    "\n",
    "Adaptor Objectives provide high-level interface, expecting both the input texts and output texts (=labels) in a form of:\n",
    "* either a `List[str]`, with the texts and labels of the matching length\n",
    "* or a paths to a `.txt` files with one sample / label per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptor.objectives.seq2seq import Sequence2Sequence\n",
    "\n",
    "seq_wiki = Sequence2Sequence(lang_module,\n",
    "                             texts_or_path=wiki_pairs.source,\n",
    "                             labels_or_path=wiki_pairs.target,\n",
    "                             val_texts_or_path=wiki_val_pairs.source,\n",
    "                             val_labels_or_path=wiki_val_pairs.target,\n",
    "                             source_lang_id=src_lang,\n",
    "                             target_lang_id=tgt_lang,\n",
    "                             batch_size=8,\n",
    "                             val_evaluators=evaluators,\n",
    "                             objective_id=\"Wiki\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same interface, we also instantiate objectives used only for evaluation. \n",
    "\n",
    "Note that in order to avoid initialising a separate head of the shared model, you need to pass `share_other_objective_head` argument with a reference to other objective that will fully share its model with the new objective. The head of the evaluation objective would otherwise never be tuned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 15:31:49 | WARNING | root | Objective Opensub-Sequence2Sequence will use SEQ2SEQ head of Wiki-Sequence2Sequence objective\n",
      "2022-05-18 15:31:50 | WARNING | root | These layers of the loaded SEQ2SEQ were not merged: []\n"
     ]
    }
   ],
   "source": [
    "eval_opensub = Sequence2Sequence(lang_module,\n",
    "                                 texts_or_path=opensub_pairs.source,\n",
    "                                 labels_or_path=opensub_pairs.target,\n",
    "                                 val_texts_or_path=opensub_val_pairs.source,\n",
    "                                 val_labels_or_path=opensub_val_pairs.target,\n",
    "                                 source_lang_id=src_lang,\n",
    "                                 target_lang_id=tgt_lang,\n",
    "                                 batch_size=8,\n",
    "                                 val_evaluators=evaluators,\n",
    "                                 share_other_objective_head=seq_wiki,\n",
    "                                 objective_id=\"Opensub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are done with the datasets, objectives and evaluators, we set up the `AdaptationArguments`. These are a small extension of ü§ó 's [TrainingArguments](https://huggingface.co/docs/transformers/main_classes/trainer?highlight=launch#transformers.TrainingArguments), the extra parameters are documented with [AdaptationArguments definition](https://github.com/gaussalgo/adaptor/blob/db33e6e439babc68fe801a8946d87116ff44f170/adaptor/utils.py#L77)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from adaptor.utils import AdaptationArguments, StoppingStrategy\n",
    "\n",
    "training_arguments = AdaptationArguments(output_dir=\"experiments\",\n",
    "                                         learning_rate=2e-5,\n",
    "                                         stopping_strategy=StoppingStrategy.ALL_OBJECTIVES_CONVERGED,\n",
    "                                         stopping_patience=5,\n",
    "                                         do_train=True,\n",
    "                                         do_eval=True,\n",
    "                                         warmup_steps=5000,\n",
    "                                         gradient_accumulation_steps=4,\n",
    "                                         logging_steps=100,\n",
    "                                         eval_steps=100,\n",
    "                                         save_steps=1000,\n",
    "                                         num_train_epochs=10,\n",
    "                                         evaluation_strategy=\"steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define a `Schedule`, defining an order of application of selected `Objective`s. If our training is a single-objective, we can pick any Schedule available - it makes no difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a main object called `Adapter`: this is again merely a small adjustment of ü§ó  [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer?highlight=launch#transformers.Trainer), that takes care of data iteration according to selected `Schedule`, collection of `Objective`s' logs or applying selected multi-objective early-stopping strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 15:31:50 | WARNING | root | Total number of train samples: 73835\n",
      "2022-05-18 15:31:50 | WARNING | root | Total number of eval samples: 200\n"
     ]
    }
   ],
   "source": [
    "from adaptor.schedules import SequentialSchedule\n",
    "from adaptor.adapter import Adapter\n",
    "\n",
    "schedule = SequentialSchedule(objectives=[seq_wiki],\n",
    "                              extra_eval_objectives=[eval_opensub],\n",
    "                              args=training_arguments)\n",
    "adapter = Adapter(lang_module, schedule, args=training_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 92290\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 230720\n",
      "2022-05-18 15:31:54 | WARNING | root | Converged objectives: []\n",
      "Wiki-Sequence2Sequence:   4%|‚ñç         | 400/9229 [00:51<17:09,  8.57batches/s, epoch=1, loss=4.65, split=train] 2022-05-18 15:32:46 | WARNING | root | Converged objectives: []\n",
      "2022-05-18 15:32:46 | WARNING | root | Evaluating...\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4617, 'learning_rate': 4.0000000000000003e-07, 'train_Wiki-Sequence2Sequence_loss': 3.1017318576574326, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00,  9.92batches/s, epoch=1, loss=1.46, split=eval]\n",
      "Opensub-Sequence2Sequence:   0%|          | 0/12 [00:00<?, ?batches/s]\u001B[A\n",
      "Opensub-Sequence2Sequence:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:00<00:00, 58.02batches/s, epoch=0, loss=0.966, split=eval]\u001B[A\n",
      "Wiki-Sequence2Sequence: 13batches [00:01, 10.74batches/s, epoch=1, loss=4.32, split=eval]                   al]\u001B[A\n",
      "Opensub-Sequence2Sequence: 13batches [00:15,  1.19s/batches, epoch=0, loss=0.737, split=eval]                  \n",
      "2022-05-18 15:33:06 | WARNING | root | Converged objectives: []\n",
      "Wiki-Sequence2Sequence:   4%|‚ñç         | 402/9229 [01:12<9:37:00,  3.92s/batches, epoch=1, loss=3.73, split=train] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6360028982162476, 'eval_runtime': 1.2126, 'eval_samples_per_second': 164.935, 'eval_steps_per_second': 164.935, 'eval_Wiki-Sequence2Sequence_loss': 2.132140645614037, 'eval_Wiki-Sequence2Sequence_num_batches': 13, 'eval_Wiki-Sequence2Sequence_BLEU-gen': 40.082749105757074, 'eval_Opensub-Sequence2Sequence_loss': 1.1398652287629933, 'eval_Opensub-Sequence2Sequence_num_batches': 13, 'eval_Opensub-Sequence2Sequence_BLEU-gen': 33.1747919975654, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:   9%|‚ñä         | 799/9229 [02:07<19:51,  7.08batches/s, epoch=1, loss=1.52, split=train]  2022-05-18 15:34:02 | WARNING | root | Converged objectives: []\n",
      "2022-05-18 15:34:02 | WARNING | root | Evaluating...\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5779, 'learning_rate': 8.000000000000001e-07, 'train_Wiki-Sequence2Sequence_loss': 2.8302815437316893, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:   0%|          | 0/12 [01:14<?, ?batches/s, epoch=1, loss=-1, split=eval]\n",
      "Wiki-Sequence2Sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00,  9.66batches/s, epoch=1, loss=1.44, split=eval]\n",
      "Opensub-Sequence2Sequence:   0%|          | 0/12 [01:00<?, ?batches/s, epoch=0, loss=-1, split=eval]\n",
      "\n",
      "Opensub-Sequence2Sequence:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:00<00:00, 57.51batches/s, epoch=0, loss=0.958, split=eval]\u001B[A\n",
      "Wiki-Sequence2Sequence: 13batches [00:01, 10.41batches/s, epoch=1, loss=4.29, split=eval]                   al]\u001B[A\n",
      "\n",
      "Opensub-Sequence2Sequence: 13batches [00:14,  1.15s/batches, epoch=0, loss=0.727, split=eval]                  \u001B[A\n",
      "2022-05-18 15:34:22 | WARNING | root | Converged objectives: []\n",
      "Wiki-Sequence2Sequence:   9%|‚ñä         | 803/9229 [02:27<6:38:52,  2.84s/batches, epoch=1, loss=2.35, split=train] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6195905208587646, 'eval_runtime': 1.2517, 'eval_samples_per_second': 159.785, 'eval_steps_per_second': 159.785, 'eval_Wiki-Sequence2Sequence_loss': 2.120600416110112, 'eval_Wiki-Sequence2Sequence_num_batches': 26, 'eval_Wiki-Sequence2Sequence_BLEU-gen': 40.468985817613984, 'eval_Opensub-Sequence2Sequence_loss': 1.1349929800400367, 'eval_Opensub-Sequence2Sequence_num_batches': 26, 'eval_Opensub-Sequence2Sequence_BLEU-gen': 33.83879196529923, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:  13%|‚ñà‚ñé        | 1200/9229 [03:20<15:16,  8.76batches/s, epoch=1, loss=3.56, split=train] 2022-05-18 15:35:15 | WARNING | root | Converged objectives: []\n",
      "2022-05-18 15:35:15 | WARNING | root | Evaluating...\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0675, 'learning_rate': 1.2000000000000002e-06, 'train_Wiki-Sequence2Sequence_loss': 2.020648795366287, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:   0%|          | 0/12 [01:11<?, ?batches/s, epoch=1, loss=-1, split=eval]\n",
      "Wiki-Sequence2Sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00,  9.52batches/s, epoch=1, loss=1.42, split=eval]\n",
      "Opensub-Sequence2Sequence:   0%|          | 0/12 [00:57<?, ?batches/s, epoch=0, loss=-1, split=eval]\n",
      "\n",
      "Opensub-Sequence2Sequence:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:00<00:00, 55.40batches/s, epoch=0, loss=0.948, split=eval]\u001B[A\n",
      "Wiki-Sequence2Sequence: 13batches [00:01, 10.31batches/s, epoch=1, loss=4.26, split=eval]                   al]\u001B[A\n",
      "Opensub-Sequence2Sequence: 13batches [00:17,  1.35s/batches, epoch=0, loss=0.707, split=eval]                  \n",
      "2022-05-18 15:35:38 | WARNING | root | Converged objectives: []\n",
      "Wiki-Sequence2Sequence:  13%|‚ñà‚ñé        | 1201/9229 [03:43<12:56:49,  5.81s/batches, epoch=1, loss=4.17, split=train]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6039254665374756, 'eval_runtime': 1.2638, 'eval_samples_per_second': 158.254, 'eval_steps_per_second': 158.254, 'eval_Wiki-Sequence2Sequence_loss': 2.1103171752049374, 'eval_Wiki-Sequence2Sequence_num_batches': 39, 'eval_Wiki-Sequence2Sequence_BLEU-gen': 40.70180013944074, 'eval_Opensub-Sequence2Sequence_loss': 1.1293619382075775, 'eval_Opensub-Sequence2Sequence_num_batches': 39, 'eval_Opensub-Sequence2Sequence_BLEU-gen': 33.59675622896459, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:  17%|‚ñà‚ñã        | 1600/9229 [04:34<19:54,  6.39batches/s, epoch=1, loss=2.71, split=train]   2022-05-18 15:36:28 | WARNING | root | Converged objectives: []\n",
      "2022-05-18 15:36:28 | WARNING | root | Evaluating...\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0801, 'learning_rate': 1.6000000000000001e-06, 'train_Wiki-Sequence2Sequence_loss': 2.0120967388153077, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:   0%|          | 0/12 [01:12<?, ?batches/s, epoch=1, loss=-1, split=eval]\n",
      "Wiki-Sequence2Sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00,  9.64batches/s, epoch=1, loss=1.4, split=eval] \n",
      "Opensub-Sequence2Sequence:   0%|          | 0/12 [00:56<?, ?batches/s, epoch=0, loss=-1, split=eval]\n",
      "\n",
      "Opensub-Sequence2Sequence:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:00<00:00, 52.20batches/s, epoch=0, loss=0.939, split=eval]\u001B[A\n",
      "Wiki-Sequence2Sequence: 13batches [00:01, 10.20batches/s, epoch=1, loss=4.25, split=eval]                  val]\u001B[A\n",
      "\n",
      "Opensub-Sequence2Sequence: 13batches [00:22,  1.72s/batches, epoch=0, loss=0.69, split=eval]                   \u001B[A\n",
      "2022-05-18 15:36:56 | WARNING | root | Converged objectives: []\n",
      "Wiki-Sequence2Sequence:  17%|‚ñà‚ñã        | 1602/9229 [05:02<12:03:57,  5.70s/batches, epoch=1, loss=6.33, split=train]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5907896757125854, 'eval_runtime': 1.2792, 'eval_samples_per_second': 156.343, 'eval_steps_per_second': 156.343, 'eval_Wiki-Sequence2Sequence_loss': 2.100764954319367, 'eval_Wiki-Sequence2Sequence_num_batches': 52, 'eval_Wiki-Sequence2Sequence_BLEU-gen': 40.686281717602974, 'eval_Opensub-Sequence2Sequence_loss': 1.1243891773315577, 'eval_Opensub-Sequence2Sequence_num_batches': 52, 'eval_Opensub-Sequence2Sequence_BLEU-gen': 33.59989581829224, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:  22%|‚ñà‚ñà‚ñè       | 2000/9229 [05:55<28:28,  4.23batches/s, epoch=1, loss=3.29, split=train]   2022-05-18 15:37:49 | WARNING | root | Converged objectives: []\n",
      "2022-05-18 15:37:49 | WARNING | root | Evaluating...\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3024, 'learning_rate': 2.0000000000000003e-06, 'train_Wiki-Sequence2Sequence_loss': 3.0922449231147766, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:   0%|          | 0/12 [01:19<?, ?batches/s, epoch=1, loss=-1, split=eval]\n",
      "Wiki-Sequence2Sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00,  9.63batches/s, epoch=1, loss=1.38, split=eval]\n",
      "Opensub-Sequence2Sequence:   0%|          | 0/12 [00:58<?, ?batches/s, epoch=0, loss=-1, split=eval]\n",
      "\n",
      "Opensub-Sequence2Sequence:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:00<00:00, 51.90batches/s, epoch=0, loss=0.932, split=eval]\u001B[A\n",
      "Wiki-Sequence2Sequence: 13batches [00:01, 10.18batches/s, epoch=1, loss=4.23, split=eval]                   al]\u001B[A\n",
      "\n",
      "Opensub-Sequence2Sequence: 13batches [00:18,  1.45s/batches, epoch=0, loss=0.676, split=eval]                  \u001B[A\n",
      "2022-05-18 15:38:13 | WARNING | root | Converged objectives: []\n",
      "Wiki-Sequence2Sequence:  22%|‚ñà‚ñà‚ñè       | 2002/9229 [06:19<10:29:03,  5.22s/batches, epoch=1, loss=2.19, split=train]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5825088024139404, 'eval_runtime': 1.2816, 'eval_samples_per_second': 156.059, 'eval_steps_per_second': 156.059, 'eval_Wiki-Sequence2Sequence_loss': 2.0929031051122227, 'eval_Wiki-Sequence2Sequence_num_batches': 65, 'eval_Wiki-Sequence2Sequence_BLEU-gen': 40.74483165473145, 'eval_Opensub-Sequence2Sequence_loss': 1.120223727593055, 'eval_Opensub-Sequence2Sequence_num_batches': 65, 'eval_Opensub-Sequence2Sequence_BLEU-gen': 34.08044916118936, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:  26%|‚ñà‚ñà‚ñå       | 2400/9229 [07:16<28:38,  3.97batches/s, epoch=1, loss=2.96, split=train]   2022-05-18 15:39:11 | WARNING | root | Converged objectives: []\n",
      "2022-05-18 15:39:11 | WARNING | root | Evaluating...\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7079, 'learning_rate': 2.4000000000000003e-06, 'train_Wiki-Sequence2Sequence_loss': 3.840408110618591, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:   0%|          | 0/12 [01:20<?, ?batches/s, epoch=1, loss=-1, split=eval]\n",
      "Wiki-Sequence2Sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00,  9.74batches/s, epoch=1, loss=1.37, split=eval]\n",
      "Opensub-Sequence2Sequence:   0%|          | 0/12 [01:02<?, ?batches/s, epoch=0, loss=-1, split=eval]\n",
      "\n",
      "Opensub-Sequence2Sequence:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:00<00:00, 57.67batches/s, epoch=0, loss=0.935, split=eval]\u001B[A\n",
      "Wiki-Sequence2Sequence: 13batches [00:01, 10.45batches/s, epoch=1, loss=4.21, split=eval]                   al]\u001B[A\n",
      "\n",
      "Opensub-Sequence2Sequence: 13batches [00:15,  1.21s/batches, epoch=0, loss=0.671, split=eval]                  \u001B[A\n",
      "2022-05-18 15:39:31 | WARNING | root | Converged objectives: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5757427215576172, 'eval_runtime': 1.2486, 'eval_samples_per_second': 160.176, 'eval_steps_per_second': 160.176, 'eval_Wiki-Sequence2Sequence_loss': 2.085502403668868, 'eval_Wiki-Sequence2Sequence_num_batches': 78, 'eval_Wiki-Sequence2Sequence_BLEU-gen': 40.566049366399504, 'eval_Opensub-Sequence2Sequence_loss': 1.1173508686897082, 'eval_Opensub-Sequence2Sequence_num_batches': 78, 'eval_Opensub-Sequence2Sequence_BLEU-gen': 34.30814750204521, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:  30%|‚ñà‚ñà‚ñà       | 2799/9229 [08:29<11:44,  9.13batches/s, epoch=1, loss=1.96, split=train]   2022-05-18 15:40:24 | WARNING | root | Converged objectives: []\n",
      "2022-05-18 15:40:24 | WARNING | root | Evaluating...\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3469, 'learning_rate': 2.8000000000000003e-06, 'train_Wiki-Sequence2Sequence_loss': 2.4922434031963348, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:   0%|          | 0/12 [01:11<?, ?batches/s, epoch=1, loss=-1, split=eval]\n",
      "Wiki-Sequence2Sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00,  9.71batches/s, epoch=1, loss=1.37, split=eval]\n",
      "Opensub-Sequence2Sequence:   0%|          | 0/12 [00:57<?, ?batches/s, epoch=0, loss=-1, split=eval]\n",
      "\n",
      "Opensub-Sequence2Sequence:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:00<00:00, 57.50batches/s, epoch=0, loss=0.93, split=eval]\u001B[A\n",
      "Wiki-Sequence2Sequence: 13batches [00:01, 10.48batches/s, epoch=1, loss=4.2, split=eval]                    al]\u001B[A\n",
      "Opensub-Sequence2Sequence: 13batches [00:18,  1.44s/batches, epoch=0, loss=0.66, split=eval]                   \n",
      "2022-05-18 15:40:48 | WARNING | root | Converged objectives: []\n",
      "Wiki-Sequence2Sequence:  30%|‚ñà‚ñà‚ñà       | 2802/9229 [08:54<6:25:04,  3.59s/batches, epoch=1, loss=2.04, split=train]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5681531429290771, 'eval_runtime': 1.2444, 'eval_samples_per_second': 160.724, 'eval_steps_per_second': 160.724, 'eval_Wiki-Sequence2Sequence_loss': 2.078510567382142, 'eval_Wiki-Sequence2Sequence_num_batches': 91, 'eval_Wiki-Sequence2Sequence_BLEU-gen': 40.604685723278365, 'eval_Opensub-Sequence2Sequence_loss': 1.1148359710043603, 'eval_Opensub-Sequence2Sequence_num_batches': 91, 'eval_Opensub-Sequence2Sequence_BLEU-gen': 33.81431821416742, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:  35%|‚ñà‚ñà‚ñà‚ñç      | 3199/9229 [09:52<13:58,  7.19batches/s, epoch=1, loss=1.21, split=train]  2022-05-18 15:41:46 | WARNING | root | Converged objectives: []\n",
      "2022-05-18 15:41:46 | WARNING | root | Evaluating...\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.399, 'learning_rate': 3.2000000000000003e-06, 'train_Wiki-Sequence2Sequence_loss': 2.7137348473072054, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:   0%|          | 0/12 [01:21<?, ?batches/s, epoch=1, loss=-1, split=eval]\n",
      "Wiki-Sequence2Sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00,  9.76batches/s, epoch=1, loss=1.37, split=eval]\n",
      "Opensub-Sequence2Sequence:   0%|          | 0/12 [01:03<?, ?batches/s, epoch=0, loss=-1, split=eval]\n",
      "\n",
      "Opensub-Sequence2Sequence:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:00<00:00, 56.64batches/s, epoch=0, loss=0.933, split=eval]\u001B[A\n",
      "Wiki-Sequence2Sequence: 13batches [00:01, 10.44batches/s, epoch=1, loss=4.19, split=eval]                   al]\u001B[A\n",
      "Opensub-Sequence2Sequence: 13batches [00:15,  1.20s/batches, epoch=0, loss=0.66, split=eval]                   \n",
      "2022-05-18 15:42:07 | WARNING | root | Converged objectives: []\n",
      "Wiki-Sequence2Sequence:  35%|‚ñà‚ñà‚ñà‚ñç      | 3202/9229 [10:12<5:03:39,  3.02s/batches, epoch=1, loss=1.35, split=train]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5618665218353271, 'eval_runtime': 1.2468, 'eval_samples_per_second': 160.413, 'eval_steps_per_second': 160.413, 'eval_Wiki-Sequence2Sequence_loss': 2.1069789761304856, 'eval_Wiki-Sequence2Sequence_num_batches': 100, 'eval_Wiki-Sequence2Sequence_BLEU-gen': 40.45699478308604, 'eval_Opensub-Sequence2Sequence_loss': 1.107856280207634, 'eval_Opensub-Sequence2Sequence_num_batches': 100, 'eval_Opensub-Sequence2Sequence_BLEU-gen': 34.267562743943515, 'epoch': 0.03}\n",
      "2022-05-18 21:05:15 | WARNING | root | Scheduler reached the given maximum number of epochs for all objectives. Triggering termination.\n",
      "2022-05-18 21:05:15 | WARNING | root | Scheduler reached a termination condition: ALL_OBJECTIVES_NUM_EPOCHS\n",
      "2022-05-18 21:05:15 | WARNING | root | Evaluating...\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 1\n",
      "{'loss': 1.1921, 'learning_rate': 1.839624313308524e-05, 'train_Wiki-Sequence2Sequence_loss': 1.2053922072052956, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wiki-Sequence2Sequence:   0%|          | 0/12 [01:49<?, ?batches/s, epoch=10, loss=-1, split=eval]\n",
      "Wiki-Sequence2Sequence:   8%|‚ñä         | 1/12 [00:00<00:00, 35.24batches/s, epoch=11, loss=0.764, split=eval]\n",
      "Opensub-Sequence2Sequence:   0%|          | 0/12 [01:47<?, ?batches/s, epoch=0, loss=-1, split=eval]\n",
      "Wiki-Sequence2Sequence:   1%|          | 100/9229 [00:28<13:43, 11.08batches/s, epoch=11, loss=0.469, split=train]2022-05-18 21:05:37 | WARNING | root | Scheduler reached the given maximum number of epochs for all objectives. Triggering termination.\n",
      "2022-05-18 21:05:37 | WARNING | root | Scheduler reached a termination condition: ALL_OBJECTIVES_NUM_EPOCHS\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "2022-05-18 21:05:37 | WARNING | root | Scheduler reached the given maximum number of epochs for all objectives. Triggering termination.\n",
      "2022-05-18 21:05:37 | WARNING | root | Scheduler reached a termination condition: ALL_OBJECTIVES_NUM_EPOCHS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7644965052604675, 'eval_runtime': 0.0305, 'eval_samples_per_second': 261.927, 'eval_steps_per_second': 261.927, 'eval_Wiki-Sequence2Sequence_loss': 1.5943953630328178, 'eval_Wiki-Sequence2Sequence_num_batches': 100, 'eval_Wiki-Sequence2Sequence_BLEU-gen': 39.88782615413746, 'eval_Opensub-Sequence2Sequence_loss': 1.5059486478567123, 'eval_Opensub-Sequence2Sequence_num_batches': 100, 'eval_Opensub-Sequence2Sequence_BLEU-gen': 24.481207223719124, 'epoch': 1.0}\n",
      "{'train_runtime': 20023.1852, 'train_samples_per_second': 46.092, 'train_steps_per_second': 11.523, 'train_loss': 1.647409159342448, 'train_Wiki-Sequence2Sequence_loss': 1.2053922072052956, 'train_Wiki-Sequence2Sequence_num_batches': 20, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23100, training_loss=1.647409159342448, metrics={'train_runtime': 20023.1852, 'train_samples_per_second': 46.092, 'train_steps_per_second': 11.523, 'total_flos': 0.0, 'train_loss': 1.647409159342448})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training terminates when the selected `StoppingStrategy` is satisfied. There is a slightly larger list of options to pick from, to cover the wider variety of multi-objective situations. See the [StoppingStrategy options](https://github.com/gaussalgo/adaptor/blob/db33e6e439babc68fe801a8946d87116ff44f170/adaptor/utils.py#L19).\n",
    "\n",
    "Let's quickly check if the training was terminated by a number of epochs (as the log says -- note the `Scheduler reached a termination condition` message in the log), or our `stopping_strategy=StoppingStrategy.ALL_OBJECTIVES_CONVERGED` (according to BLEU, since we've initialised it with `decides_convergence=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval BLEU\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.Series(seq_wiki.evaluations_history[\"eval\"][evaluators[0]]).plot(figsize=(15, 7), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eval loss\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.Series(seq_wiki.evaluations_history[\"eval\"][\"loss\"]).plot(figsize=(15, 7), grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised adaptation\n",
    "\n",
    "In this experiment we'll see hiw far can we get without a large set of aligned supervised texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-cs-en/resolve/main/config.json from cache at /home/xstefan3/.cache/huggingface/transformers/8574c5a6a6364b41827117f086812030143d2b25b92206d8b3f6d684745e8066.7bb9e3260d1abcad4452c2a159fd1668543f0b66b704f6ef4197dc58ccd92176\n",
      "Model config MarianConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      62508\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 62508,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 62508,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 62509\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-cs-en/resolve/main/source.spm from cache at /home/xstefan3/.cache/huggingface/transformers/de8aa4e2d80168b5e21926507904d37e0029e2cd9109288dc8bca1a53bf16fc2.f7b8f33623917afa192c98e8cdb7110a96e4ef9f1f49ad2548a62236c818d814\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-cs-en/resolve/main/target.spm from cache at /home/xstefan3/.cache/huggingface/transformers/a622ae1fe7c735110523a7462cefcb232a7c57d64bf782bb5e5b18d88199cd57.802f2650721ec7e21ef8b2ec0a6adbdfa24815d20e3bc4b2994a4e7323207ae2\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-cs-en/resolve/main/vocab.json from cache at /home/xstefan3/.cache/huggingface/transformers/cb57aa91d734e65f18e4a475380972973fc9e427cd781bb8017e5a65e00fbb40.12e5a9c0c42c3467972154314fa3a3c04b52a6735d1cd7216a6facbb0de44ce3\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-cs-en/resolve/main/tokenizer_config.json from cache at /home/xstefan3/.cache/huggingface/transformers/05a1c2f3d66206e92f99c7a3a7498ceafb8081ce786d4cc6a277da08e09599a0.c5753583caba2512f03c1dd8a50811762daadc90baedc6c606c7b137759e05e4\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-cs-en/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-cs-en/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-cs-en/resolve/main/tokenizer.json from cache at None\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-cs-en/resolve/main/config.json from cache at /home/xstefan3/.cache/huggingface/transformers/8574c5a6a6364b41827117f086812030143d2b25b92206d8b3f6d684745e8066.7bb9e3260d1abcad4452c2a159fd1668543f0b66b704f6ef4197dc58ccd92176\n",
      "Model config MarianConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      62508\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 62508,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 62508,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 62509\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from adaptor.lang_module import LangModule\n",
    "\n",
    "lang_module = LangModule(\"Helsinki-NLP/opus-mt-%s-%s\" % (src_lang, tgt_lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `BackTranslation` objective, that first translates the target texts into the source language using given `BackTranslator` instance. This way, we do not need to provide the objective an aligned set of samples, but we still need unsupervised data of the target language.\n",
    "\n",
    "Of course, the eventual quality of such-trained model also heavily depends on a quaility of the BackTranslator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/config.json from cache at /home/xstefan3/.cache/huggingface/transformers/827ff170f0b812bc7aeb5b56274c2626143bc2254efa5d4df89cec71c2fec9ac.7bb9e3260d1abcad4452c2a159fd1668543f0b66b704f6ef4197dc58ccd92176\n",
      "Model config MarianConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      62508\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 62508,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 62508,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 62509\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/source.spm from cache at /home/xstefan3/.cache/huggingface/transformers/36561bb31c2702debc859e3fc9c11ac45adbb3a4744a0e2b52584026792a0441.802f2650721ec7e21ef8b2ec0a6adbdfa24815d20e3bc4b2994a4e7323207ae2\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/target.spm from cache at /home/xstefan3/.cache/huggingface/transformers/dd1424e7a7dd9e5fe463a64e61e76c5ba9bfd10fd37050320ddc510cff8f57ba.f7b8f33623917afa192c98e8cdb7110a96e4ef9f1f49ad2548a62236c818d814\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/vocab.json from cache at /home/xstefan3/.cache/huggingface/transformers/9865631fc3589f67952dcb08d792b7153a2017f43719cb789e2e982709c2177d.12e5a9c0c42c3467972154314fa3a3c04b52a6735d1cd7216a6facbb0de44ce3\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/tokenizer_config.json from cache at /home/xstefan3/.cache/huggingface/transformers/394726bea97903848d60aae65c9f2689bd34c0b22a19f5c5b845f0e0187081d8.4aad148346bf95da5e433798f4585a3f0286cac6642930115fe59af0be15b5f9\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/tokenizer.json from cache at None\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/config.json from cache at /home/xstefan3/.cache/huggingface/transformers/827ff170f0b812bc7aeb5b56274c2626143bc2254efa5d4df89cec71c2fec9ac.7bb9e3260d1abcad4452c2a159fd1668543f0b66b704f6ef4197dc58ccd92176\n",
      "Model config MarianConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      62508\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 62508,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 62508,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 62509\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/config.json from cache at /home/xstefan3/.cache/huggingface/transformers/827ff170f0b812bc7aeb5b56274c2626143bc2254efa5d4df89cec71c2fec9ac.7bb9e3260d1abcad4452c2a159fd1668543f0b66b704f6ef4197dc58ccd92176\n",
      "Model config MarianConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      62508\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 62508,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 62508,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 62509\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-en-cs/resolve/main/pytorch_model.bin from cache at /home/xstefan3/.cache/huggingface/transformers/8492de3383cb030e21a06a70f9c03669fdbce63c2ff0ece9a6175c8110720d9d.8771d1d8b1e0bfe440e0606c5f42988d8a31d2fbb37a1fa6b4a131d247363d7d\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-cs.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "2022-05-18 21:05:50 | WARNING | root | Objective Wiki-Back-BackTranslation will use SEQ2SEQ head of Wiki-Sequence2Sequence objective\n",
      "2022-05-18 21:05:50 | WARNING | root | Wiki-Back-BackTranslation expects target-language texts as input_texts_or_path. This is not further checked. \n"
     ]
    }
   ],
   "source": [
    "from adaptor.objectives.backtranslation import BackTranslation, BackTranslator\n",
    "\n",
    "backtrans_wiki = BackTranslation(lang_module,\n",
    "                                 back_translator=BackTranslator(\"Helsinki-NLP/opus-mt-%s-%s\" % (tgt_lang, src_lang)),\n",
    "                                 texts_or_path=wiki_pairs.target,\n",
    "                                 val_texts_or_path=wiki_val_pairs.target,\n",
    "                                 batch_size=8,\n",
    "                                 share_other_objective_head=seq_wiki,\n",
    "                                 objective_id=\"Wiki-Back\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the other pieces of puzzle remain the same. We'll initialise extra evaluation objective though, to be able to compare the logs of the two evaluation objectives based on their history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 21:05:50 | WARNING | root | Objective Opensub-Sequence2Sequence will use SEQ2SEQ head of Wiki-Sequence2Sequence objective\n",
      "2022-05-18 21:05:50 | WARNING | root | These layers of the loaded SEQ2SEQ were not merged: []\n"
     ]
    }
   ],
   "source": [
    "eval_opensub_unsup = Sequence2Sequence(lang_module,\n",
    "                                 texts_or_path=opensub_pairs.source,\n",
    "                                 labels_or_path=opensub_pairs.target,\n",
    "                                 val_texts_or_path=opensub_val_pairs.source,\n",
    "                                 val_labels_or_path=opensub_val_pairs.target,\n",
    "                                 source_lang_id=src_lang,\n",
    "                                 target_lang_id=tgt_lang,\n",
    "                                 batch_size=8,\n",
    "                                 val_evaluators=evaluators,\n",
    "                                 share_other_objective_head=seq_wiki,\n",
    "                                 objective_id=\"Opensub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 21:05:50 | WARNING | root | Total number of train samples: 73835\n",
      "2022-05-18 21:05:50 | WARNING | root | Total number of eval samples: 200\n"
     ]
    }
   ],
   "source": [
    "from adaptor.schedules import SequentialSchedule\n",
    "from adaptor.adapter import Adapter\n",
    "\n",
    "schedule = SequentialSchedule(objectives=[backtrans_wiki],\n",
    "                              extra_eval_objectives=[eval_opensub_unsup],\n",
    "                              args=training_arguments)\n",
    "adapter = Adapter(lang_module, schedule, args=training_arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this training will take somewhat longer, since the back-translation of the samples in the first epoch is performed on-the-fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "adapter.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Let's see how the supervised adaptation is doing in comparison with the unsupervised BackTranslation objective.\n",
    "\n",
    "Thanks to Adaptor's separation to objectives, we can conveniently take a look at the validation accuracies of the two experiments, separately on in-distribution and out-of-distribution BLEU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wiki_bleus_sup = pd.Series(seq_wiki.evaluations_history['eval'][evaluators[0]])\n",
    "wiki_bleus_unsup = pd.Series(backtrans_wiki.evaluations_history['eval'][evaluators[0]])\n",
    "\n",
    "index = range(0, len(wiki_bleus_sup)*training_arguments.eval_steps, training_arguments.eval_steps)\n",
    "\n",
    "wiki_bleus_sup.index = index\n",
    "wiki_bleus_unsup.index = index\n",
    "\n",
    "wiki_bleus_sup.plot(figsize=(14, 5), grid=True, ylim=(0.75, 0.9), color=\"blue\", label=\"In-domain validation BLEU of supervised adaptation\")\n",
    "wiki_bleus_unsup.plot(figsize=(14, 5), grid=True, ylim=(0.75, 0.9), color=\"blue\", alpha=0.7, label=\"in-domain validation BLEU of unsupervised adaptation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensub_bleus_sup = pd.Series(eval_opensub.evaluations_history['eval'][evaluators[0]])\n",
    "opensub_bleus_unsup = pd.Series(eval_opensub_unsup.evaluations_history['eval'][evaluators[0]])\n",
    "\n",
    "index = range(0, len(opensub_bleus_sup)*training_arguments.eval_steps, training_arguments.eval_steps)\n",
    "\n",
    "opensub_bleus_sup.index = index\n",
    "opensub_bleus_unsup.index = index\n",
    "\n",
    "opensub_bleus_sup.plot(figsize=(14, 5), grid=True, ylim=(0.75, 0.9), color=\"blue\", label=\"Out-of-domain validation BLEU of supervised adaptation\")\n",
    "opensub_bleus_unsup.plot(figsize=(14, 5), grid=True, ylim=(0.75, 0.9), color=\"blue\", alpha=0.7, label=\"Out-of-domain validation BLEU of unsupervised adaptation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Finally, we evaluate the out models of both trainings, to see which performs better on a held-out set.\n",
    "\n",
    "Note, that in both cases, we've used `stopping_strategy=StoppingStrategy.ALL_OBJECTIVES_CONVERGED`, so the evaluated model is the model after passing this stopping criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_model = seq_wiki.compatible_head_model\n",
    "unsupervised_model = backtrans_wiki.compatible_head_model\n",
    "\n",
    "evaluator = BLEU(additional_sep_char=\"‚ñÅ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bleu(dataset, model) -> float:\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "\n",
    "    for src_text, ref_text in zip(wiki_test_pairs.source, wiki_test_pairs.target):\n",
    "        references.append(ref_text)\n",
    "        inputs = lang_module.tokenizer(src_text, truncation=True, return_tensors=\"pt\").to(test_device)\n",
    "        outputs = translator_model.generate(**inputs)\n",
    "        translations = lang_module.tokenizer.batch_decode(outputs, remove_special_tokens=True)\n",
    "        hypotheses.append(translations[0])\n",
    "\n",
    "    bleu = evaluator.evaluate_str(references, hypotheses)\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-distribution BLEUs: supervised & unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_id_sup = evaluate_bleu(opensub_test_pairs, supervised_model)\n",
    "print(\"Test BLEU of supervised model on Wiki: %s\" % bleu_id_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_id_unsup = evaluate_bleu(wiki_test_pairs, unsupervised_model)\n",
    "print(\"Test BLEU of supervised model on Wiki: %s\" % bleu_id_unsup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-distribution BLEUs: supervised & unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_ood_sup = evaluate_bleu(opensub_test_pairs, supervised_model)\n",
    "print(\"Test BLEU of supervised model on Wiki: %s\" % bleu_ood_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bleu_ood_unsup = evaluate_bleu(opensub_test_pairs, unsupervised_model)\n",
    "print(\"Test BLEU of supervised model on Wiki: %s\" % evaluate_bleu(opensub_test_pairs, unsupervised_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}